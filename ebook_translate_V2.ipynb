{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the rise of e-books, reading literature from around the world has become much more accessible, but the language barrier still remains.\n",
    "\n",
    "This work aims to help for this issue.\n",
    "\n",
    "We will use the Dracula 1897 edition avaliable on https://www.gutenberg.org/ebooks/345\n",
    "\n",
    "Project Gutenberg is an online library of free e-books that aims to make classic literature more widely available. It was founded in 1971 by Michael Hart, and is the oldest digital library. The project's mission is to digitize and make available books that are in the public domain, which means that the copyright has expired and the books are no longer under exclusive rights.\n",
    "\n",
    "Please, this work is just embryonal and, maybe, doesn't solve the translation satisfactorily. In fact, it's just a simple and automatic way to use Google Translate or another translator provider, with means that it will reproduce their deficiencies and issues.\n",
    "\n",
    "Keep in mind that there is a far difference between translation and localization. Much of the work of a professional translator is not just translating a sentence, but transposing the idea closed on it. And there are writers who usually write their books in layers or profound analogies, while their culture lies in it.\n",
    "\n",
    "Even an AI or Deep Learning system will need s much more fancy solution for this issue.\n",
    "\n",
    "So, this algorithm is just a first step but, for a really better result, it is proper that you have a reasonable command of the objective language so as not to incur misunderstandings in your study.\n",
    "\n",
    "At last, but importantly, each ebook has its own structure, so depending on it, the translation could not perform as expected. A more general solution is coming (I hope so), but, for now, please analyze your ebook format before using this algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT FRAME\n",
    "\n",
    "from ebooklib import epub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import translators as ts \n",
    "import translators.server as tss\n",
    "\n",
    "\n",
    "# this ons will be important, trust me\n",
    "import scipy.stats as stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOADING FRAME\n",
    "\n",
    "epub_path=os. getcwd()+\"/Dracula - Bram Stoker.epub\"\n",
    "#epub_path=os. getcwd()+\"/pg345-images-3.epub\"\n",
    "book = epub.read_epub(epub_path)\n",
    "\n",
    "#for analyzes reason I produce a Dataset with the structure of the book\n",
    "chapters=pd.DataFrame(columns=[\"Chapter\", \"Type\"])\n",
    "info=[]\n",
    "for item in book.get_items():\n",
    "    info.append(item.get_name())\n",
    "    info.append(item.get_type())\n",
    "    chapters.loc[len(chapters)]=info\n",
    "    info=[]\n",
    "\n",
    "print(chapters)\n",
    "\n",
    "#taking a look if I took the right document\n",
    "title = book.get_metadata('DC', 'title')[0][0]\n",
    "author = book.get_metadata('DC', 'creator')[0][0]\n",
    "print(f\"Title: {title}\")\n",
    "print(f\"Author: {author}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAKING LIST OF CHAPTER\n",
    "# (see EbookLib Documentatio Release 0.17 page 16 )\n",
    "ch_list=np.array(chapters.Chapter.iloc[np.where(chapters.Type==9)])\n",
    "#if you want to start and stop in a specific chapters, please uncomment the line above e adapt it \n",
    "#refute=np.array(range(0,8))\n",
    "#ch_list=ch_list[9:len(ch_list)-1]\n",
    "\n",
    "#checking the result\n",
    "print(ch_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOADING CHAPTER(S) TO A VARIABLE\n",
    "import ebooklib\n",
    "from bs4 import BeautifulSoup\n",
    "txt_ready=\"\"\n",
    "document=\"6844709148999201933_345-h-1.htm.xhtml\"\n",
    "\n",
    "# if you want more than one chapter please ajust the ch_list above and substitute ue document variable\n",
    "for item in book.get_items():\n",
    "    if (item.get_type() == ebooklib.ITEM_DOCUMENT) and (item.get_name()== document ):\n",
    "        soup = BeautifulSoup(item.get_content(), 'html.parser')\n",
    "        txt_ready = txt_ready + soup.get_text()     \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANALYZE FRAME#\n",
    "all_txt=txt_ready.split(\"\\n\")\n",
    "p_size=[]\n",
    "s_size=[]\n",
    "pz_count=0\n",
    "sz_count=0\n",
    "for paragraph in all_txt:\n",
    "    p_size.append(len(paragraph))\n",
    "    sentence=paragraph.split(\".\")\n",
    "    if len(paragraph)<3:\n",
    "        pz_count+=1\n",
    "    for s in sentence:\n",
    "        if len(s)<3:\n",
    "            sz_count+=1\n",
    "        s_size.append(len(s))\n",
    "        \n",
    "print(\"Description of paragraphs\")\n",
    "print(stats.describe(p_size))\n",
    "print(\"There are {} paragraphs without words\".format(pz_count))\n",
    "print(\"Description of sentences\")\n",
    "print(stats.describe(s_size))\n",
    "print(\"There are {} sentences without words\".format(sz_count))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRANSLATION FRAME#\n",
    "from_language, to_language = 'en', 'pt'\n",
    "\n",
    "all_txt=txt_ready.split(\"\\n\")\n",
    "total=len(txt_ready)\n",
    "translation=\"\"\n",
    "max_size=5000 #max size allowed by google translate\n",
    "flag_dot=False\n",
    "\n",
    "for paragraph in all_txt:\n",
    "    size_translation=len(translation)\n",
    "    size_paragraph=len(paragraph)\n",
    "    print(\" Status{}% translated\".format(size_translation/total*100))\n",
    "    #checking if it's now above the provider max characters size and, at least, that\n",
    "    #we will translate, at least, one word\n",
    "    if size_paragraph<=max_size and size_paragraph>3:\n",
    "        sentence=tss.google(paragraph, from_language, to_language)\n",
    "        translation = translation + \"\\n\" + sentence \n",
    "    #if the  paragraph is larger than the limit asked by the provider\n",
    "    #we break it in sentences\n",
    "    elif size_paragraph>max_size:        \n",
    "        sentence=paragraph.split(\".\")\n",
    "        for s in sentence:        \n",
    "            if len(s)<round(max_size*0.7):\n",
    "                wait_s=wait_s+s\n",
    "        #if s starts with a number this means that:\n",
    "        #1- the sentence starts with a float number\n",
    "        #2- it's an enumerated sentence\n",
    "            if int(s[0]):\n",
    "                wait_s=s\n",
    "                flag_dot=True\n",
    "                pass\n",
    "            if flag_dot:\n",
    "                lag_dot=False\n",
    "                s= wait_s+s           \n",
    "            trans_sentence=tss.google(s, from_language, to_language)\n",
    "            print(trans_sentence)\n",
    "            translation = translation + \". \" + trans_sentence\n",
    "        translation=translation+ \"\\n\"\n",
    "    clear_output()\n",
    "    \n",
    "\n",
    "with open(\"translated_ebook.txt\", \"w\") as file:\n",
    "    file.write(translation)\n",
    "\n",
    "file.close()\n",
    "print(\"We finished\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d16c9f31056bcc7e327079c9b5d94fa92914cc57792a846d31dacd63bbce8039"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
